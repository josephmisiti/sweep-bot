import asyncio
from _typeshed import Incomplete
from aiohttp import BytesIOPayload
from aiohttp.abc import AbstractStreamWriter as AbstractStreamWriter
from collections.abc import Generator
from modal.exception import ExecutionError as ExecutionError
from modal_utils.hash_utils import UploadHashes as UploadHashes
from typing import AsyncIterator, BinaryIO, List, Optional

MAX_OBJECT_SIZE_BYTES: Incomplete
LARGE_FILE_LIMIT: Incomplete
BLOB_MAX_PARALLELISM: int

class BytesIOSegmentPayload(BytesIOPayload):
    initial_seek_pos: Incomplete
    segment_start: Incomplete
    segment_length: Incomplete
    read_lock: Incomplete
    chunk_size: Incomplete
    def __init__(self, bytes_io: BinaryIO, read_lock: asyncio.Lock, segment_start: int, segment_length: int, chunk_size: int = ...) -> None: ...
    num_bytes_read: int
    def reset_state(self) -> None: ...
    def reset_on_error(self) -> Generator[None, None, None]: ...
    @property
    def size(self) -> int: ...
    def md5_checksum(self): ...
    async def write(self, writer: AbstractStreamWriter): ...
    def remaining_bytes(self): ...

async def perform_multipart_upload(data_file: BinaryIO, *, content_length: int, max_part_size: int, part_urls: List[str], completion_url: str): ...
def get_content_length(data: BinaryIO): ...
async def blob_upload(payload: bytes, stub) -> str: ...
async def blob_upload_file(file_obj: BinaryIO, stub) -> str: ...
async def blob_download(blob_id, stub) -> bytes: ...
async def blob_iter(blob_id, stub) -> AsyncIterator[bytes]: ...

class FileUploadSpec:
    filename: str
    mount_filename: str
    use_blob: bool
    content: Optional[bytes]
    sha256_hex: str
    size: int
    def __init__(self, filename, mount_filename, use_blob, content, sha256_hex, size) -> None: ...

def get_file_upload_spec(filename: str, mount_filename: str) -> FileUploadSpec: ...
def use_md5(url: str) -> bool: ...
